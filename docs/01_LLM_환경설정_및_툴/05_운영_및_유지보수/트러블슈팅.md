## 트러블슈팅

### Ollama가 시작 안 됨
```bash
# 로그 확인
log stream --predicate 'process == "ollama"'

# 수동 시작
ollama serve

# brew 재설치
brew uninstall ollama && brew install ollama
```

### Docker 컨테이너가 자동 시작 안 됨
```bash
# 상태 확인
docker ps -a | grep open-webui

# 재시작
docker restart open-webui

# 로그 확인
docker logs open-webui
```

### AutoGen 에러: API 연결 불가
```bash
# Ollama 실행 확인
curl http://localhost:11434

# 모델 있는지 확인
ollama list

# 환경변수 확인
echo $ANTHROPIC_BASE_URL
echo $ANTHROPIC_API_KEY
```

### 메모리 부족
```bash
# 실행 중인 프로세스 확인
top

# 모델 크기 줄이기
ollama pull deepseek-coder-v2:7b  # 16B 대신 7B

# Docker 메모리 제한 설정
docker update --memory 30g open-webui
```

### 라우터 토큰 추정이 부정확함
```python
# 더 정확한 토큰 계산을 원하면:
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("meta-llama/Llama-2-7b")
tokens = len(tokenizer.encode(prompt))
```