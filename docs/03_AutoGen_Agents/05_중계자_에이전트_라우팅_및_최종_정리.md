# 05. 중계자 에이전트 라우팅 및 최종 정리

M4 Pro 64GB 환경에서 시스템 반응 속도와 메모리 효율을 극대화하기 위한 '중계자(Router)' 에이전트의 활용 전략과 구현 방법을 설명합니다.

## 1. 중계자(Router)의 핵심 역할

중계자는 초경량 모델(1.5b~3b)을 사용하여 시스템의 입구에서 다음과 같은 '지능형 게이트웨이' 역할을 수행합니다.

1.  **에이전트 라우팅 및 메모리 트리거 (Traffic Control)**: 요청이 신규 설계인지 단순 수정인지 판단하여 Architect 호출 여부를 결정합니다.
2.  **컨텍스트 압축 및 요약 (Context Management)**: 대화 기록을 요약하여 다음 에이전트에게 전달함으로써 토큰 낭비를 줄이고 추론 속도를 높입니다.
3.  **결과 포맷 검수 (Sanity Check)**: 에이전트의 출력이 규격(JSON 등)에 맞는지 검사하여 파이프라인 중단을 방지합니다.

## 2. 중계자용 시스템 프롬프트 및 라우팅 로직

### 2.1 시스템 프롬프트 (System Prompt)

중계자에게 에이전시 운영자 페르소나를 부여하고, **2026년 최신 기술 기준의 난이도 판단 로직**을 탑재하여 판단 능력을 극대화합니다. (상세 판단 기준은 [05-1. 난이도 판단 매뉴얼](./05-1_중계자_난이도_판단_매뉴얼_및_Modelfile.md) 참조)

```text
너는 로컬 LLM 에이전시의 총괄 운영자다. 사용자의 요청과 2026년 기준 참조 문서를 분석하여 [ARCHITECT, CODER, TESTER, FRONTIER] 중 누구에게 보낼지 결정하라.

[비판적 사고 및 지시사항]
1. [탐색 및 대조]: 제공된 2026년 사양이 기존 방식과 충돌하는지 확인하라. (내가 준 문서가 항상 우선이다)
2. [난이도 판정]: 아래 조건 중 하나라도 해당하면 [난이도: 상]으로 분류하고 FRONTIER 또는 52B Planner를 추천하라.
   - 2026년형 파괴적 변경(Breaking Changes) 포함
   - 5개 이상의 모듈 간 의존성 재설계 필요
   - 보안/성능 최적화가 핵심인 복합 아키텍처 설계
3. [경제적 운영]: 단순 문법 교체나 단일 파일 수정은 [난이도: 하]로 분류하여 CODER(32B)에게 즉시 할당하라.
4. [최종 보고]: 분석 결과에 따라 최적의 에이전트를 선택하고, 필요시 모델 스왑 승인을 요청하라.

응답은 반드시 다음 JSON 형식으로만 해:
{"difficulty": "상/중/하", "next_agent": "AGENT_NAME", "reason": "분석 결과 요약", "requires_swap": true/false, "use_frontier": true/false}
```

### 2.2 파이썬 라우팅 구현 예시

```python
import ollama
import json
import os

def router_agent(user_input, agent_status="IDLE"):
    # 1. 중계자(1.5b) 호출 - 항상 메모리에 상주(keep_alive=-1)
    response = ollama.generate(
        model='qwen2.5:1.5b', 
        system="위의 운영 3대 엄격 규칙 포함 시스템 프롬프트 입력",
        prompt=f"현재 상태: {agent_status}\n요청: {user_input}",
        format='json',
        keep_alive='-1' 
    )
    
    decision = json.loads(response['response'])
    next_step = decision['next_agent']
    
    # [규칙 1] Busy 상태면 대기
    if agent_status == "BUSY" and decision['requires_swap']:
        print("⏳ 상주 모델이 작업 중입니다. 완료될 때까지 52B 소환을 대기합니다.")
        return "WAIT"

    # [규칙 3] 52B 소환 시 승인제
    if decision['requires_swap']:
        confirm = input(f"⚠️ {next_step} 소환을 위해 상주 모델을 언마운트하시겠습니까? (y/n): ")
        if confirm.lower() != 'y':
            print("취소되었습니다. 로컬 상주 모델로 계속 진행합니다.")
            return "CANCEL"
        
        # [규칙 2] 스냅샷 저장
        save_snapshot(user_input)

    # 하이브리드 외주(Frontier) 처리
    if decision.get('use_frontier'):
        print("⚠️ 고난도 작업으로 판단되어 Frontier LLM(GPT-4o)에 요청합니다.")
        return call_frontier_api(user_input)
```

### 2.3 스냅샷 저장 로직 (Snapshot)

```python
def save_snapshot(context):
    """모델 스왑 전 현재 문맥 저장"""
    snapshot = {
        "last_requirement": context,
        "working_files": ["app/main.py"], # 예시
        "last_error": "None",
        "timestamp": "2026-02-10"
    }
    with open("shared/temp_context.json", "w") as f:
        json.dump(snapshot, f)
    print("📸 체크포인트가 shared/temp_context.json에 저장되었습니다.")
```
        # Architect 등 무거운 모델을 부를 때 상주 모델(Coder, Reviewer) 잠시 내림
        print("무거운 모델 로드를 위해 기존 에이전트 메모리 반납 중...")
        run_architect(user_input)
    else:
        # 상주해 있는 Coder나 Tester에게 바로 전달
        if next_step == 'CODER':
            run_coder(user_input)
        elif next_step == 'TESTER':
            run_tester(user_input)
```

## 3. TDD 실패 로그 분석 및 자동화

테스트 실패 시 중계자가 에러 로그를 분석하여 "단순 수정"인지 "설계 변경"인지 판단하여 루프를 자동화합니다.

### 3.1 분석 시스템 프롬프트

```text
너는 TDD 워크플로우의 관제탑이야. 테스트 결과를 보고 다음 중 하나를 결정해:

[비판적 사고 지침]
- 코더가 인터넷에서 참조한 라이브러리 용법이나 로직이 공식 문서와 충돌하여 발생한 에러인지 우선 확인하라.
- 검색된 해결책을 맹목적으로 적용하기보다, 현재 프로젝트 구조와의 정합성을 먼저 따져라.
- [FIX_CODE]: 단순 논리 오류나 문법 에러일 때 (CODER에게 전달, swap: false)
- [RE_ARCHITECT]: 현재 설계로는 테스트 통과가 불가능한 구조적 결함일 때 (ARCHITECT에게 전달, swap: true)
- [ENV_ERROR]: 라이브러리 미설치나 경로 문제 등 환경 오류일 때 (USER에게 조치 요청)

결정 사항:
1. [FIX_CODE]: 단순 논리 오류나 문법 에러일 때
2. [RE_ARCHITECT]: 현재 설계로는 테스트 통과가 불가능한 구조적 결함일 때
3. [ENV_ERROR]: 라이브러리 미설치나 경로 문제 등 환경 오류일 때

응답은 반드시 JSON: {"action": "ACTION_NAME", "analysis": "비판적 에러 분석 결과", "requires_swap": boolean}
```

### 3.2 분석 로직 구현

```python
def analyze_test_failure(test_log, code_context):
    """테스트 실패 로그를 분석하여 다음 단계를 결정하는 함수"""
    
    # 중계자(1.5b)가 에러 원인 파악
    response = ollama.generate(
        model='qwen2.5:1.5b',
        system="TDD 분석 시스템 프롬프트 내용",
        prompt=f"[로그]\n{test_log}\n[코드]\n{code_context}",
        format='json',
        keep_alive='-1'
    )
    
    result = json.loads(response['response'])
    action = result['action']
    
    if action == "FIX_CODE":
        # 상주 중인 Coder에게 즉시 피드백 (0초 지연)
        return call_coder_for_fix(test_log, code_context)
    elif action == "RE_ARCHITECT":
        # 설계 결함이면 Architect 로드 (메모리 스왑 발생)
        return call_architect_redesign(test_log, code_context)
```

## 4. 최종 정리 에이전트 (Documenter)

협업 결과물(설계, 코드, 테스트 결과)을 취합하여 사람이 읽기 좋은 Markdown 리포트를 생성합니다.

### 4.1 구현 로직

```python
def generate_final_report(plan, code, test_result):
    """모든 에이전트의 결과물을 취합해 MD 문서 생성"""
    
    context = f"[PLAN]\n{plan}\n[CODE]\n{code}\n[TEST]\n{test_result}"
    
    # 상주 중인 Reviewer(14b) 또는 Router(1.5b) 활용
    response = ollama.generate(
        model='qwen3-coder:14b', 
        system="너는 프로젝트 기술 문서화 전문가야. 목차에 맞게 마크다운 문서를 작성해.",
        prompt=f"데이터 바탕으로 완료 보고서 작성:\n{context}",
        keep_alive='2h'
    )
    
    with open("Project_Success_Report.md", "w", encoding="utf-8") as f:
        f.write(response['response'])
```

## 5. M4 Pro 64GB 최적화 팁

1.  **지능적 메모리 스왑**: 64GB 환경에서 52GB 모델(Architect)은 임계치에 도달하므로, `keep_alive: 0`을 사용하여 작업 후 즉시 메모리를 반납해야 합니다.
2.  **중계자 상주**: 1.5b 모델은 메모리 점유가 미미하므로 `keep_alive: -1`로 항상 띄워두어 0초 반응 속도를 확보합니다.
3.  **비동기 처리**: Local Executor가 테스트를 실행하는 동안 중계자가 다음 작업을 준비하도록 `asyncio`를 활용하면 전체 사이클 속도가 비약적으로 향상됩니다.
