# 10. 최종 구축 체크리스트 및 마무리

시스템의 모든 구성 요소(LLM 선택, 메모리 관리, 샌드박스, 툴 연동, TDD 루프, 모니터링)가 설계되었습니다. 실제 구현 및 가동 전 마지막으로 점검해야 할 항목들입니다.

## 1. 하드웨어 및 인프라 체크리스트 (M4 Pro 기준)

*   [ ] **VRAM Limit 확보**: GPU 통합 메모리 제한을 확장했는지 확인합니다.
    ```bash
    sudo sysctl iogpu.UnifiedMemoryLimitBytes=57982058496  # 54GB 예시
    ```
*   [ ] **Ollama Keep-alive 설정**: 
    - Architect (간헐적 사용): `keep_alive=0` (메모리 즉시 해제)
    - Coder/Tester (잦은 사용): `keep_alive=-1` (메모리 상주)
*   [ ] **Docker 샌드박스**: 컨테이너가 로컬 프로젝트 디렉토리와 정상적으로 마운트되었는지, 네트워크 격리가 되어 있는지 확인합니다.
*   [ ] **Ollama 설치 및 모델 다운로드**: 
    - [ ] Ollama 설치 완료
    - [ ] Qwen 2.5 시리즈 (7B, 14B, 32B) 다운로드
    - [ ] 임베딩 모델 (`multi-qa-mpnet-base-dot-v1` 또는 `bge-m3`) 다운로드
*   [ ] **Docker 및 UI 실행**: 
    - [ ] Docker Desktop 설치 완료
    - [ ] Open WebUI 컨테이너 실행 (`http://localhost:3000`)

## 2. 소프트웨어 및 에이전트 설정 체크리스트

*   [ ] **Python 환경**: `pip install rich pytest` 등 필요한 라이브러리 설치 확인
*   [ ] **Git 초기화**: 프로젝트 루트가 Git 저장소로 초기화되어 있는지 확인 (`git init`)
*   [ ] **에이전트 페르소나**: Modelfile에 최적화된 시스템 프롬프트([09번 문서](./09_Qwen3_최적화_시스템_프롬프트.md))가 적용되었는지 확인
*   [ ] **통신 규격(Matching) 확인**: 에이전트 간 주고받는 JSON 데이터 형식이 일치하는지 확인
*   [ ] **비판적 사고 주입**: 모든 에이전트 프롬프트에 '근거 오염 방지' 지침이 포함되었는지 확인
*   [ ] **RAG 및 웹 검색 설정**: 실시간 지식 확장이 필요한 경우 [12. 로컬 LLM 인터넷 연결 가이드](./12_로컬_LLM_인터넷_연결_및_실시간_지식_확장.md)의 체크리스트를 완료했는지 확인

## 3. 시스템 가동 및 운영

모든 체크리스트를 완료했다면, 이제 자율 주행 개발 시스템을 가동할 준비가 끝났습니다.

1.  **초기 프롬프트 입력**: 사용자 요구사항을 `Architect`에게 전달합니다.
2.  **모니터링 감상**: 터미널에 스트리밍되는 에이전트들의 협업 과정을 지켜봅니다.
3.  **최종 결과 확인**: 모든 테스트를 통과하고 자동으로 커밋된 코드를 검토합니다.

---

이제 모든 설계가 완료되었습니다. 바로 구현에 착수하시겠습니까? 아니면 특정 모델의 페르소나나 로직을 더 정교하게 다듬는 과정이 필요하신가요?
AI의 답변에는 오류가 있을 수 있으니, 중요한 로직은 반드시 교차 검증을 권장합니다.
