# 13. 프론티어 LLM 하이브리드 협업 가이드 (Frontier SOS)

로컬 모델(Qwen)이 논리적 한계에 부딪히거나 극도로 복잡한 설계가 필요할 때, GPT-4o나 Claude 3.5 Sonnet 같은 프론티어 모델에게 도움을 요청하는 '하이브리드 협업 체계'를 구축합니다.

---

## 1. 하이브리드 구조의 핵심 전략

비용 효율성과 데이터 보안을 유지하면서 결정적인 순간에만 고성능 지능을 빌려 쓰는 전략입니다.

- **로컬 처리 (90%)**: 일상적인 코딩, 로그 분석, 단위 테스트, 기술 문서 초안 작성.
- **프론티어 요청 (10%)**:
    - 완전히 새로운 시스템의 전체 아키텍처 설계.
    - 로컬 모델이 3번 이상 해결하지 못한 고난도 버그 트래킹.
    - 최신 라이브러리(2025년 이후)의 파괴적 변경사항 대응.
    - 복잡한 수학적 최적화 및 알고리즘 설계.

---

## 2. 🛡️ 에이전시 운영 3대 엄격 규칙 (Protocol)

M4 Pro 64GB 환경에서 대형 모델(52B) 호출 시 상주 모델(32B, 14B)의 작업 흐름이 끊기지 않도록 하는 핵심 규칙입니다.

### 규칙 1. [상주 모델 강제 잠금 (Lock Phase)]
Router는 '작업 중(Status: Busy)' 상태인 에이전트가 있을 때는 절대로 52B Planner를 소환할 수 없습니다.
- **프로세스**: Router가 고난도 문제를 감지해도, Coder(32B)나 Reviewer(14B)가 작업을 마치고 `STATUS: IDLE` 신호를 보낼 때까지 큐(Queue)에서 대기합니다.
- **이유**: 작업 도중 모델이 언마운트되면 생성 중인 코드나 KV 캐시가 소실되어 리소스 낭비가 발생합니다.

### 규칙 2. [체크포인트 강제 저장 (Snapshot)]
52B를 소환하기 직전, Router는 반드시 현재까지의 모든 진행 상황을 스냅샷으로 저장해야 합니다.
- **저장 항목**: `shared/current_task.json` 또는 `temp_context.md`에 현재 구현 파일명, 직전 에러 로그, 사용자의 마지막 요구사항을 기록.
- **이유**: 52B 퇴장 후 32B가 다시 로드되었을 때, 이 스냅샷을 읽고 즉시 문맥을 복구(Context Restore)하기 위함입니다.

### 규칙 3. [52B 호출 승인제 (Human-in-the-Loop)]
Router가 독단적으로 대형 모델을 부르지 못하도록 사용자의 최종 승인 단계를 거칩니다.
- **로직**: Router가 `[WARNING: 52B Planner 소환이 필요합니다. 상주 모델이 언마운트됩니다. 승인하시겠습니까?]`라고 질문합니다.
- **이유**: 불필요한 메모리 스왑 시간(약 10~20초) 낭비를 방지하고 비용을 통제합니다.

---

## 3. 🔄 수정된 지능형 바톤 터치 워크플로우

1.  **Router(7B) 분석**: 질문의 난이도 판별. (바로 52B를 부르지 않음)
2.  **상태 점검**: "Dev1(32B) 작업 완료 여부" 확인.
3.  **스냅샷 저장**: 현재 대화 맥락과 코드를 `temp_context.md`에 백업.
4.  **사용자 승인**: 52B 로드 및 상주 모델 언마운트에 대한 승인 획득.
5.  **Planner(52B) 로드**: 32B, 14B가 내려가도 파일에 백업이 있으므로 안전.
6.  **Planner 작업**: 설계 완료 후 `shared/blueprint.md`에 결과 저장.
7.  **Planner 즉시 퇴장**: 작업 완료 즉시 `keep_alive=0`으로 메모리 완전 비우기.
8.  **상주 모델 복귀**: Router(7B)와 Dev1(32B)이 복귀하여 `temp_context.md` + `blueprint.md`를 읽고 작업 재개.

---

## 4. 컨텍스트 오버플로우 방지 전략 (Context Sharing)

작은 모델(7B, 14B)이 방대한 설계서로 인해 '정보 과부하'가 걸리는 것을 방지합니다.

- **Executive Summary 강제**: Planner가 분석 종료 시, 구현 모델을 위한 [핵심 액션 아이템 5줄] 요약을 출력하도록 프롬프팅합니다.
- **지식 저장소와 지시서의 분리**: 상세 설계는 파일(`.md`)에 저장하고, 에이전트에게는 "파일을 참조하여 구체적인 이 부분만 수정해"라고 짧게 지시합니다.
- **압축 임베딩 활용**: 중계자(Router)가 긴 대화 내용을 요약하여 컨텍스트를 초기화한 뒤 깨끗한 상태로 전달합니다.

---

## 5. 구현 방법 (Open WebUI & Ollama)

### 방법 1: Open WebUI '연결(Connections)' 활용
- **설정**: `Settings -> Connections`에서 API Key 입력.
- **사용법**: 모델 메뉴에서 `gpt-4o` 등을 선택하여 즉시 전환.

### 방법 2: Router(중계자)의 외주 권한 자동화
- **로직**: 분석 -> 난이도 '상' 판단 -> 사용자 승인 -> API 호출 함수 실행.

---

> **운영 핵심**: "메모리는 지워져도, 파일은 영원하다." 모델 전환 시의 기억상실은 공유 파일 시스템을 통해 극복합니다.
