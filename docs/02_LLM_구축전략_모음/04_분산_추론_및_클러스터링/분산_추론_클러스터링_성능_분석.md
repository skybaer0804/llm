# 맥북 분산 추론(클러스터링)시 성능의 역설

맥북 M2(24GB)와 맥 미니 M4 Pro(64GB)를 연결하여 분산 추론(Distributed Inference), 즉 클러스터링을 구성하시려는군요. 결론부터 말씀드리면, **M2 맥북에서도 동일하게 메모리 설정을 해주어야 합니다.**

하지만 일반적인 단일 실행과는 조금 다른 관점에서 접근해야 합니다. 상세 내용을 정리해 드릴게요.

## 1. M2 맥북에서도 메모리 설정이 필요한 이유

클러스터링을 하면 모델의 레이어(Layer)를 두 기기가 나누어서 처리하게 됩니다. 예를 들어 총 80개의 레이어가 있다면 M4 Pro가 60개를, M2가 20개를 담당하는 식입니다.

이때 M2 맥북이 할당받은 레이어들을 GPU 메모리에 올리려면, 마찬가지로 macOS의 기본 제한(약 60~70%)에 걸릴 수 있습니다. 따라서 M2에서도 가용 범위를 넓혀줘야 병목 현상을 줄일 수 있습니다.

### M2(24GB)를 위한 터미널 명령어:

```bash
# 24GB 중 약 21GB를 GPU가 사용할 수 있도록 설정
sudo sysctl iogpu.wired_limit_mb=21504
```

## 2. 클러스터 구성 시 고려할 점 (성능의 역설)

두 대를 연결하면 메모리 용량은 합쳐져서 더 큰 모델을 돌릴 수 있지만, **추론 속도(Tokens per second)**는 오히려 느려질 가능성이 높습니다.

*   **대역폭의 차이**: M4 Pro의 내부 메모리 대역폭은 매우 빠르지만, 두 기기를 잇는 네트워크(썬더볼트 혹은 10Gb 이더넷)는 그보다 훨씬 느립니다.
*   **병목 현상**: M4 Pro가 자기 몫을 다 계산해도 M2가 계산해서 데이터를 보내줄 때까지 기다려야 합니다.

### 추천 시나리오:

64GB 단일 기기에서 도저히 안 돌아가는 **매우 큰 모델(예: 120B 이상)**을 돌릴 때만 클러스터링을 사용하시고, 70B급 모델까지는 M4 Pro 64GB 단일 기기에서 최적화해서 돌리는 것이 훨씬 빠릅니다.
