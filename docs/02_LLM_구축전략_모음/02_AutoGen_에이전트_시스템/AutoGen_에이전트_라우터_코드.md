## ğŸ¯ ì´ ë¼ìš°í„°ì˜ í•µì‹¬ ê¸°ëŠ¥

### 1ï¸âƒ£ **ì‘ì—… íƒ€ì…ë³„ ìë™ ë¼ìš°íŒ…**

```python
# ì˜ˆì‹œ: ìë™ ë¼ìš°íŒ… ê·œì¹™

"design" â†’ Qwen3-Coder-Next (52GB, Architect)
"code" â†’ Qwen3-Coder 32B (19GB, Coder)
"review" â†’ Qwen3 14B (9GB, Reviewer)
```


### 2ï¸âƒ£ **ë©”ëª¨ë¦¬ ìë™ ê´€ë¦¬**

```python
# Architect ë¶ˆëŸ¬ì˜¬ ë•Œ
1. ë‹¤ë¥¸ ëª¨ë“  ëª¨ë¸ ì–¸ë¡œë“œ
2. 52GB ì—¬ìœ  í™•ì¸
3. ë¡œë“œ í›„ ì‘ì—…

# Coder/Reviewer ë¶ˆëŸ¬ì˜¬ ë•Œ
1. Architect ì–¸ë¡œë“œ
2. 19GB + 9GB = 28GB í™•ì¸
3. ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥
```


### 3ï¸âƒ£ **í¸ë¦¬í•œ API ì—”ë“œí¬ì¸íŠ¸**

```bash
# ì§ì ‘ í˜¸ì¶œ
curl -X POST http://localhost:8000/architect \
  -H "Content-Type: application/json" \
  -d '{"prompt": "ì„¤ê³„í•´ì¤„ë˜?"}'

# ë°°ì¹˜ ì²˜ë¦¬ (ì„¤ê³„ â†’ êµ¬í˜„ â†’ ê²€ìˆ˜)
curl -X POST http://localhost:8000/batch \
  -H "Content-Type: application/json" \
  -d '[{...}, {...}, {...}]'
```


***

## ğŸ“‹ ìš”ì²­ ì˜ˆì‹œ (Python)

### ì‹œë‚˜ë¦¬ì˜¤: ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ êµ¬ì¶•

```python
import httpx

# 1ï¸âƒ£ Architect: ì„¤ê³„ ë‹¨ê³„
arch_response = httpx.post(
    "http://localhost:8000/architect",
    json={
        "prompt": """
ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì„¤ê³„:
- User Service (JWT ì¸ì¦)
- Order Service (ì£¼ë¬¸ ì²˜ë¦¬)
- Product Service (ìƒí’ˆ ê´€ë¦¬)
- gRPC í†µì‹ , PostgreSQL, Redis

â†’ ì „ì²´ ì•„í‚¤í…ì²˜ + ë‹¨ê³„ë³„ êµ¬í˜„ ê³„íš
        """,
        "max_tokens": 3000
    }
).json()

print(f"Architect ì‘ë‹µ (ì†Œìš”ì‹œê°„: {arch_response['latency_ms']}ms)")
print(arch_response['response'][:500])  # ì²« 500ì

# 2ï¸âƒ£ Coder: êµ¬í˜„ ë‹¨ê³„
code_response = httpx.post(
    "http://localhost:8000/coder",
    json={
        "prompt": f"""
User Service êµ¬í˜„ (FastAPI):

ìš”êµ¬ì‚¬í•­:
- JWT í† í° ê¸°ë°˜ ì¸ì¦
- ë¹„ë°€ë²ˆí˜¸ bcrypt í•´ì‹±
- PostgreSQL ì—°ë™
- Redis ìºì‹±

ì•„í‚¤í…ì²˜ ì»¨í…ìŠ¤íŠ¸:
{arch_response['response'][:1000]}

â†’ ì™„ì„±ëœ ì½”ë“œ ì‘ì„±
        """,
        "max_tokens": 2500
    }
).json()

print(f"\nCoder ì‘ë‹µ (ì†Œìš”ì‹œê°„: {code_response['latency_ms']}ms)")

# 3ï¸âƒ£ Reviewer: ê²€ìˆ˜ ë‹¨ê³„
review_response = httpx.post(
    "http://localhost:8000/reviewer",
    json={
        "prompt": f"""
ë‹¤ìŒ ì½”ë“œë¥¼ ë¦¬ë·°í•´ì£¼ì„¸ìš”:

{code_response['response'][:2000]}

ì²´í¬ í•­ëª©:
- ë³´ì•ˆ ì·¨ì•½ì 
- SQL ì¸ì ì…˜
- ì—ëŸ¬ í•¸ë“¤ë§
- ì„±ëŠ¥ ìµœì í™”
- í…ŒìŠ¤íŠ¸ í•„ìš”ì„±

â†’ ë¬¸ì œì  + ê°œì„ ì•ˆ ì œì‹œ
        """,
        "task_type": "review"
    }
).json()

print(f"\nReviewer ì‘ë‹µ (ì†Œìš”ì‹œê°„: {review_response['latency_ms']}ms)")
print(review_response['response'])
```


***

## ğŸš€ AutoGenì—ì„œ ì‚¬ìš©í•˜ê¸°

### autogen_team.pyì— ë¼ìš°í„° í†µí•©

```python
from autogen import AssistantAgent, GroupChat, GroupChatManager

# LLM ë¼ìš°í„°ë¡œ ì—°ê²°
llm_config = {
    "config_list": [
        {
            "model": "gpt-4",  # ì´ë¦„ì€ ìƒê´€ì—†ìŒ
            "base_url": "http://localhost:8000",  # ë¼ìš°í„° í¬íŠ¸
            "api_type": "openai",
            "api_key": "dummy-key"
        }
    ]
}

# Architect ì—ì´ì „íŠ¸
architect = AssistantAgent(
    name="Architect",
    system_message="ë‹¹ì‹ ì€ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì„¤ê³„ìì…ë‹ˆë‹¤. ìš”êµ¬ì‚¬í•­ì„ ë°›ì•„ ì•„í‚¤í…ì²˜ë¥¼ ì„¤ê³„í•˜ì„¸ìš”.",
    llm_config=llm_config
)

# Coder ì—ì´ì „íŠ¸
coder = AssistantAgent(
    name="Coder",
    system_message="ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ ê°œë°œìì…ë‹ˆë‹¤. ì„¤ê³„ì— ë”°ë¼ ì½”ë“œë¥¼ êµ¬í˜„í•˜ì„¸ìš”.",
    llm_config=llm_config
)

# Reviewer ì—ì´ì „íŠ¸
reviewer = AssistantAgent(
    name="Reviewer",
    system_message="ë‹¹ì‹ ì€ ì½”ë“œ ë¦¬ë·°ì–´ì…ë‹ˆë‹¤. ë³´ì•ˆ, ì„±ëŠ¥, ìŠ¤íƒ€ì¼ì„ ê²€ìˆ˜í•˜ì„¸ìš”.",
    llm_config=llm_config
)

# ê·¸ë£¹ ì±„íŒ… ì„¤ì •
groupchat = GroupChat(
    agents=[architect, coder, reviewer],
    messages=[],
    max_round=10
)

manager = GroupChatManager(groupchat=groupchat, llm_config=llm_config)

# ì´ìŠˆ ì²˜ë¦¬ ì‹œì‘
user = UserProxyAgent(name="User", human_input_mode="TERMINATE")
user.initiate_chat(
    manager,
    message="ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ êµ¬í˜„í•´ì¤„ë˜?"
)
```


***

## ğŸ“Š ë¡œê¹… \& ëª¨ë‹ˆí„°ë§

ë¼ìš°í„°ëŠ” ìë™ìœ¼ë¡œ ë¡œê·¸ë¥¼ ë‚¨ê¹ë‹ˆë‹¤:

```bash
# ì‹¤ì‹œê°„ ë¡œê·¸ í™•ì¸
tail -f /tmp/router.log

# ìƒ˜í”Œ ë¡œê·¸ ì¶œë ¥
2026-02-10 12:49:00 - router - INFO - [ROUTING] task=design â†’ model=qwen3-coder-next:q4_K_M | reason=task_type=design, urgency=normal
2026-02-10 12:49:01 - router - INFO - [MEMORY CHECK] í˜„ì¬: 15.2/64GB
2026-02-10 12:49:01 - router - INFO - [MODEL] LOAD: qwen3-coder-next:q4_K_M (52GB)
2026-02-10 12:49:45 - router - INFO - [RESPONSE] agent=Architect, latency=44230ms, tokens~1024
2026-02-10 12:50:00 - router - INFO - [MODEL] UNLOAD: qwen3-coder-next:q4_K_M
2026-02-10 12:50:01 - router - INFO - [ROUTING] task=code â†’ model=qwen3-coder:32b | reason=task_type=code, urgency=normal
```


***

## âœ… ì •ë¦¬: ì „ì²´ íŒŒì¼ êµ¬ì„±

ì´ì œ ë‹¹ì‹ ì´ ì¤€ë¹„í•´ì•¼ í•  íŒŒì¼ë“¤:

```
your-project/
â”œâ”€â”€ router.py                  # â­ ìƒˆë¡œ ë§Œë“  ë¼ìš°í„° (ì´ íŒŒì¼)
â”œâ”€â”€ autogen_team.py            # AutoGen ì—ì´ì „íŠ¸ íŒ€ ì„¤ì •
â”œâ”€â”€ docker-compose.yml         # Docker ì„¤ì • (ê¸°ì¡´ ë¬¸ì„œ)
â”œâ”€â”€ M4-Pro-AutoGen-Setup.md    # ì„¤ì • ê°€ì´ë“œ
â””â”€â”€ ğŸ“„ M4-Pro-Optimal-3LLM.md  # LLM ì„ íƒ ê°€ì´ë“œ (updated)
```


***

**âœ¨ ì™„ë£Œ!** ì´ì œ ë‹¹ì‹ ì˜ ì‹œìŠ¤í…œì€:

âœ… **Qwen3-Coder-Next** (Architect, ì„¤ê³„)
âœ… **Qwen3-Coder 30B** (Coder, êµ¬í˜„)
âœ… **Qwen3 14B** (Reviewer, ê²€ìˆ˜)
âœ… **ë¼ìš°í„°ê°€ ìë™ìœ¼ë¡œ ë©”ëª¨ë¦¬ ê´€ë¦¬** (ìˆœì°¨ + ë³‘ë ¬ ìµœì í™”)
âœ… **AutoGen ì™„ì „ ìë™í™”** (GitHub ì´ìŠˆ â†’ ìë™ ì²˜ë¦¬)

ëª¨ë‘ M4 Pro 64GBì—ì„œ **ë¬´ë£Œë¡œ 24/7 ìš´ì˜ ê°€ëŠ¥**í•©ë‹ˆë‹¤! ğŸš€

ì•„ë¬´ê±°ë‚˜ ê¶ê¸ˆí•œ ê±° ìˆìœ¼ë©´ ë” ë¬¼ì–´ë´ìš”!
