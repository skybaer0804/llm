## 1. LLM 모델 최적 선택 (2026년 Qwen3-Coder-Next 기반 리뉴얼)

### 1.1 목표와 전제

당신의 시스템:

- MacBook Pro M4 Pro / 64GB 통합 메모리
- 모든 추론 **100% 로컬 (Ollama)**
- 프레임워크: **Microsoft AutoGen**
- 역할: 설계자(Architect) – 개발자(Coder) – 검수자/테스터(Reviewer/Tester) **3명 에이전트**

설계 철학:

1. **최고의 “설계 뇌” 1개** → Qwen3-Coder-Next
2. **중량·속도가 균형 잡힌 “개발자” 1개** → Qwen3-Coder 32B
3. **가벼우면서도 꼼꼼한 “검수자” 1개** → Qwen3 14B

그리고 **64GB 메모리를 넘기지 않기 위해, “동시 상주”가 아니라 AutoGen 라우터가 순차로 호출**하는 구조를 기본값으로 합니다.

***

### 1.2 최종 추천 구성 (요약)

#### ✅ 에이전트 3명 + 모델 매핑

| 역할 | AutoGen 에이전트 이름 | Ollama 모델 | 용도 | 추정 메모리(모델 사이즈 기준) |
| :-- | :-- | :-- | :-- | :-- |
| 🧠 설계자 (Architect) | `Planner` | `qwen3-coder-next:q4_K_M` | 요구사항 분석, 아키텍처 설계, 장기 컨텍스트 추론 | 약 52GB[^3_1][^3_2] |
| 💻 개발자 (Coder) | `Dev1_Senior` | `qwen3-coder:32b` (기본) | 기능 구현, 리팩터링, 문맥 보존 코딩 | 약 19GB[^3_3] |
| 👀 검수/테스터 (Reviewer/Tester) | `Dev2_Reviewer` or `Tester_QA` | `qwen3:14b` | 코드 리뷰, 버그 지적, 테스트 코드 생성 | 약 9~10GB[^3_4] |

> 메모리 포인트
> - Qwen3-Coder-Next `q4_K_M`는 Ollama 기준 모델 사이즈가 약 52GB로 표기됩니다.[^3_1][^3_2]
> - Qwen3-Coder 32B는 약 19GB, Qwen3 14B는 약 9.3GB 입니다.[^3_3][^3_4]
> - 따라서 **세 모델을 동시에 항상 띄워두는 건 64GB 시스템에서 비현실적**이고,
>   **Architect(Qwen3-Coder-Next)는 “필요할 때만 불러쓰는 단일 브레인”으로 설계**하는 것이 안전합니다.

***

### 1.3 왜 이 조합인가?

#### ① Qwen3-Coder-Next → “설계자 전용 브레인”

- **에이전트형 코딩에 최적화된 최신 Qwen 계열**
    - 80B MoE 구조(실제 활성 파라미터는 일부만 사용)
    - 256K 토큰 컨텍스트로 **대형 코드베이스/긴 사양 문서를 통째로 물린 후 설계** 가능[^3_2][^3_1]
- SWE-Bench, 도구 사용, 환경 상호작용 등 **“에이전트 LLM” 벤치마크에서 상위권**
- 설계자 역할에 요구되는 것:
    - 요구사항 해석
    - 시스템 분해(모듈, 서비스, 레이어)
    - 구현 단계/우선순위 설계
→ 이 부분은 **속도보다 정확도와 장기 문맥 유지가 훨씬 중요**하므로,
가장 무거운 Qwen3-Coder-Next를 여기 한 번만 쓰는 게 효율적입니다.


#### ② Qwen3-Coder 32B → 메인 개발자

- Qwen3 계열 중 **코딩 특화 버전**으로, 실제 코드 생성·리팩터링에서 매우 강함[^3_3]
- 32B 사이즈는:
    - 7B/14B보다 **복잡한 리팩터링·멀티파일 작업에 강하고**,
    - 72B/80B급보다 **메모리·속도 모두 현실적인 sweet spot**
- 약 19GB 사이즈로,
    - Architect(Qwen3-Coder-Next)가 메모리에서 내려간 상태라면
**Dev1 + Dev2(검수자) 병렬 정도는 충분히 가능**한 수준입니다.


#### ③ Qwen3 14B → 가볍고 꼼꼼한 검수자/테스터

- Qwen3 14B는 일반적인 코드 리뷰, 스타일 체크, 간단한 테스트 코드 자동 생성에는 충분한 수준의 성능을 제공합니다.[^3_4]
- 9~10GB 수준이라,
    - Dev1(32B)와 함께 띄워도 시스템 전체 메모리 여유를 확보하기 쉽습니다.
- Reviewer/Tester의 역할 특성상:
    - 코드 전체를 새로 짜는 것보다
    - “문제 있는 부분 탐지 + 개선 제안”이 주 업무이므로
    - **중간 크기의 범용 모델이 오히려 안정적**입니다.

***

### 1.4 메모리·운영 전략

#### 1) Architect는 “순차 호출”이 기본\n\n- `qwen3-coder-next:q4_K_M`는 모델 자체 사이즈가 약 52GB로,\n**macOS + 기타 프로세스를 고려하면 사실상 단독으로만 안정적으로 운용** 가능합니다.[^3_1][^3_2]\n- 따라서:\n\n1. GitHub 이슈/요청을 받아서 **Planner(Architect)**가 설계/로드맵을 작성\n2. 설계가 끝나면 **해당 단계에서 Qwen3-Coder-Next는 더 이상 사용하지 않음**\n3. 이후 Dev1/Dev2는 **Qwen3-Coder 32B + Qwen3 14B 조합으로 작업 이어가기**\n\n이 구조를 AutoGen 라우터에서:\n\n- `task_type=plan / design` → `qwen3-coder-next:q4_K_M`\n- `task_type=code` → `qwen3-coder:32b`\n- `task_type=review/test` → `qwen3:14b`\n\n이렇게 분배해 주면 됩니다.\n\n#### 2) Dev1 + Dev2는 병렬도 허용 가능\n\n- Dev1(32B, 약 19GB) + Dev2(14B, 약 9~10GB)를 동시에 띄워도\n**대략 30GB 선**이라,\n    - OS/기타 앱 포함해도 64GB 안에서 안정적인 선입니다.\n- 실제 AutoGen 그룹채팅에서는:\n    - “Dev1이 코드 작성 → Dev2가 즉시 리뷰” 같은 **짧은 턴 기반 왕복 패턴**이 많기 때문에\n    - 두 모델을 같이 띄워두고 토큰만 번갈아 쓰는 구성이 편합니다.\n\n***\n
### 1.5 기존 구성 대비 업그레이드 포인트\n\n기존 문서의 구성:\n\n- Llama 4 Scout (메인 브레인)\n- DeepSeek-Coder V2 (개발자)\n- Gemma3 27B (검수자)\n\n새 구성:\n\n- **Qwen3-Coder-Next (Architect 전용)**\n- **Qwen3-Coder 32B (메인 개발자)**\n- **Qwen3 14B (검수/테스터)**\n\n업그레이드 포인트:\n\n- **설계/계획 단계**:\n    - 기존 Llama 4 Scout → **Qwen3-Coder-Next로 업그레이드**\n    - 256K 컨텍스트 + agentic tuning 덕분에\n“긴 이슈 설명 + 기존 코드 구조 + TODO 리스트”를 한 번에 보고 설계 가능\n- **코딩 단계**:\n    - DeepSeek-Coder V2도 훌륭하지만,\n    - Qwen3-Coder 32B는 **Qwen3 계열과의 일관성 + 코드/언어 혼합 작업에 강점**이 있습니다.[^3_3]\n- **검수 단계**:\n    - Gemma3 27B 대신 Qwen3 14B를 쓰면\n        - Qwen 계열로 **프롬프트 스타일을 통일**할 수 있고,\n        - 메모리 여유가 늘어나며,\n        - 다국어/코드 이해 능력도 충분합니다.[^3_4]\n\n***\n\n### 1.6 한 줄 요약\n\n> **“AutoGen + Qwen3-Coder-Next”라는 방향은 유지하되,\n> Qwen3-Coder-Next는 설계자(Architect) 1개로만 쓰고,\n> 실제 코딩/검수는 Qwen3-Coder 32B + Qwen3 14B로 맡기는 3에이전트 구조가\n> M4 Pro 64GB 환경에서 가장 현실적이면서도 강력한 조합이다.**